{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stablecoin Billionaires<br> Descriptive Analysis of the Ethereum-based Stablecoin ecosystem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## by Anton Wahrst√§tter, 01.07.2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tether\n",
    "tether_chunk_0 = 'data/tether/transfer/0_tether_transfer_4638568-8513778.csv'\n",
    "tether_chunk_1 = 'data/tether/transfer/1_tether_transfer_8513799-8999999.csv'\n",
    "tether_chunk_2 = 'data/tether/transfer/2_tether_transfer_9000000-9799999.csv'\n",
    "tether_chunk_3 = 'data/tether/transfer/3_tether_transfer_9800000-10037842.csv'\n",
    "tether_chunk_4 = 'data/tether/transfer/4_tether_transfer_10037843-10176690.csv'\n",
    "tether_chunk_5 = 'data/tether/transfer/5_tether_transfer_10176691-10370273.csv' \n",
    "tether_chunk_0_1 = 'data/tether/transfer/0_tether_transfer_4638568-8999999.csv'\n",
    "tether_transfer = 'data/tether/transfer/tether_transfers.csv'\n",
    "tether_issue = 'data/tether/issue/tether_issue.csv'\n",
    "tether_destroyedblackfunds = 'data/tether/destroyedblackfunds/tether_destroyedblackfunds.csv'\n",
    "tether_tx_count_to = 'plots/tether/tether_tx_count_to.csv'\n",
    "tether_tx_count_from = 'plots/tether/tether_tx_count_from.csv'\n",
    "\n",
    "#usdc\n",
    "usdc_transfer = 'data/usdc/transfer/0_usdc_transfer_6082465-10370273.csv' \n",
    "usdc_mint = 'data/usdc/mint/usdc_mint.csv' \n",
    "usdc_burn = 'data/usdc/burn/usdc_burn.csv' \n",
    "usdc_tx_count_to = 'plots/usdc/usdc_tx_count_to.csv'\n",
    "usdc_tx_count_from = 'plots/usdc/usdc_tx_count_from.csv'\n",
    "\n",
    "#paxos\n",
    "paxos_transfer = 'data/paxos/transfer/0_paxos_transfer_6294931-10370273.csv' \n",
    "paxos_mint = 'data/paxos/supplyincreased/paxos_supplyincreased.csv'\n",
    "paxos_burn = 'data/paxos/supplydecreased/paxos_supplydecreased.csv'\n",
    "paxos_tx_count_to = 'plots/paxos/paxos_tx_count_to.csv'\n",
    "paxos_tx_count_from = 'plots/paxos/paxos_tx_count_from.csv'\n",
    "\n",
    "#dai\n",
    "dai_transfer = 'data/dai/transfer/0_dai_transfer_8928158-10370273.csv' \n",
    "dai_mint = 'data/dai/mint/dai_mint.csv'\n",
    "dai_burn = 'data/dai/burn/dai_burn.csv'\n",
    "dai_tx_count_to = 'plots/dai/dai_tx_count_to.csv'\n",
    "dai_tx_count_from = 'plots/dai/dai_tx_count_from.csv'\n",
    "\n",
    "#trueusd\n",
    "trueusd_transfer = 'data/trueusd/transfer/0_trueUSD_transfer_5198636-10370273.csv' \n",
    "trueusd_mint = 'data/trueusd/mint/trueusd_mint.csv'\n",
    "trueusd_mint_old = 'data/trueusd/mint/trueusd_mint_old.csv'\n",
    "trueusd_burn = 'data/trueusd/burn/trueusd_burn.csv'\n",
    "trueusd_burn_old = 'data/trueusd/burn/trueusd_burn_old.csv'\n",
    "\n",
    "#binanceusd\n",
    "binanceusd_transfer = 'data/binanceusd/transfer/0_binanceusd_transfer_8493105-10370273.csv' \n",
    "binanceusd_mint = 'data/binanceusd/supplyincreased/binanceusd_supplyincreased.csv'\n",
    "binanceusd_burn = 'data/binanceusd/supplydecreased/binanceusd_supplydecreased.csv'\n",
    "binanceusd_tx_count_to = 'plots/binanceusd/binanceusd_tx_count_to.csv'\n",
    "binanceusd_tx_count_from = 'plots/binanceusd/binanceusd_tx_count_from.csv'\n",
    "\n",
    "#husd\n",
    "husd_transfer = 'data/husd/transfer/0_husd_transfer_8174400-10370273.csv' \n",
    "husd_mint = 'data/husd/issue/husd_issue.csv'\n",
    "husd_burn = 'data/husd/redeem/husd_redeem.csv'\n",
    "husd_tx_count_to = 'plots/husd/husd_tx_count_to.csv'\n",
    "husd_tx_count_from = 'plots/husd/husd_tx_count_from.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concentrate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concentrate_data():\n",
    "    df = pd.concat([pd.read_csv(tether_chunk_0), \n",
    "                    pd.read_csv(tether_chunk_1), \n",
    "                    pd.read_csv(tether_chunk_2), \n",
    "                    pd.read_csv(tether_chunk_3), \n",
    "                    pd.read_csv(tether_chunk_4),\n",
    "                    pd.read_csv(tether_chunk_5)], ignore_index=True)\n",
    "    df.to_csv('data/tether/transfer/tether_transfers.csv', index=False)\n",
    "    return   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Transfer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#works great for up to 18 decimals\n",
    "#needs much RAM\n",
    "pd.options.mode.chained_assignment = None\n",
    "def get_balances(_df, decimals):\n",
    "    token = _df.split('/')[1]\n",
    "    print(\"Start with {}\".format(token))\n",
    "    df = pd.read_csv(_df)\n",
    "    froms = df[['txfrom', 'txvalue']]\n",
    "    froms['txvalue'] = froms['txvalue'].apply(lambda x: int(x)*-1)\n",
    "    tos = df[['txto', 'txvalue']]\n",
    "    tos['txvalue'] = tos['txvalue'].apply(lambda x: int(x))\n",
    "    outs = froms.groupby(\"txfrom\").sum().reset_index().rename(columns={\"txfrom\":\"txto\"})\n",
    "    ins = tos.groupby(\"txto\").sum().reset_index()\n",
    "    balance = outs.append(ins).groupby(\"txto\").sum()\n",
    "    balance = balance / 10**decimals\n",
    "    balance = balance.reset_index().rename(columns={\"txto\":\"address\"}).set_index(\"address\").sort_values('txvalue')\n",
    "    balance.to_csv('plots/{}/{}_balances.csv'.format(token, token))\n",
    "    \n",
    "get_balances(tether_transfer, 6)    \n",
    "get_balances(binanceusd_transfer, 18)\n",
    "get_balances(husd_transfer, 8)\n",
    "get_balances(dai_transfer, 18)\n",
    "get_balances(trueusd_transfer, 18)\n",
    "get_balances(usdc_transfer, 6)\n",
    "get_balances(paxos_transfer, 18)\n",
    "get_balances(sai_transfer, 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove burned tokens from Tether balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('plots/tether/tether_balances.csv', index_col='address')\n",
    "burn = pd.read_csv(tether_destroyedblackfunds).loc[:,['address', 'txvalue']].set_index('address')\n",
    "burn['txvalue'] = burn['txvalue'] /-10**6\n",
    "_df = df.append(burn)\n",
    "_df.loc['0xc6cde7c39eb2f0f0095f41570af89efc2c1ea828',:]=108850 # bitfinex multisig\n",
    "_df = _df.groupby(_df.index).sum().sort_values('txvalue')\n",
    "_df.to_csv('plots/tether/tether_balances.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depreciated, but needs less RAM\n",
    "# works well for small number decimal coins\n",
    "def get_balances(dflist, decimals=0, chunked=False):\n",
    "    counter = 0\n",
    "    for chunk in dflist:\n",
    "        token = chunk.split('/')[1]\n",
    "        _chunk = pd.read_csv(chunk)\n",
    "        froms = _chunk[['txfrom', 'txvalue']].set_index('txfrom')\n",
    "        froms['txvalue'] = froms['txvalue'].apply(lambda x: int(x)/(10**decimals)*-1)\n",
    "        tos =  _chunk[[ 'txto', 'txvalue']].set_index('txto')\n",
    "        tos['txvalue'] = tos['txvalue'].apply(lambda x: int(x)/(10**decimals))\n",
    "        df = tos.append(froms)\n",
    "        df = df.groupby(df.index).sum()\n",
    "        if chunked:\n",
    "            df.to_csv('plots/{}/{}_balances_chunk_{}.csv'.format(token, token, counter))\n",
    "        else:\n",
    "            df.to_csv('plots/{}/{}_balances.csv'.format(token, token))\n",
    "        counter += 1\n",
    "    return\n",
    "        \n",
    "usdt = [tether_chunk_0, tether_chunk_1, tether_chunk_2, tether_chunk_3, tether_chunk_4, tether_chunk_5]\n",
    "get_balances(usdt, chunked=True)\n",
    "get_balances([usdc_transfer])\n",
    "get_balances([paxos_transfer], 18)\n",
    "get_balances([dai_transfer])\n",
    "get_balances([trueusd_transfer], 18)\n",
    "get_balances([husd_transfer])\n",
    "get_balances([binanceusd_transfer], 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concentrate Chunks (Balances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = pd.read_csv('plots/tether/tether_balances_chunk_0.csv', index_col=0)\n",
    "bb = pd.read_csv('plots/tether/tether_balances_chunk_1.csv', index_col=0)\n",
    "cc = pd.read_csv('plots/tether/tether_balances_chunk_2.csv', index_col=0)\n",
    "dd = pd.read_csv('plots/tether/tether_balances_chunk_3.csv', index_col=0)\n",
    "ee = pd.read_csv('plots/tether/tether_balances_chunk_4.csv', index_col=0)\n",
    "ff = pd.read_csv('plots/tether/tether_balances_chunk_5.csv', index_col=0)\n",
    "df = aa.append([bb,cc,dd,ee,ff])\n",
    "df = df.groupby(df.index).sum()\n",
    "df = df.sort_values('txvalue')\n",
    "df.to_csv('plots/tether/tether_balances.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_to_tx_counter(dflist):\n",
    "    from_count = Counter()\n",
    "    to_count = Counter()\n",
    "    for chunk in dflist:\n",
    "        token = chunk.split('/')[1]\n",
    "        df = pd.read_csv(chunk)\n",
    "        froms = Counter(df['txfrom'])\n",
    "        tos = Counter(df['txto'])\n",
    "        from_count = from_count + froms\n",
    "        to_count = to_count + tos\n",
    "\n",
    "    df_from = pd.DataFrame(dict(from_count).values(), index=dict(from_count).keys()).rename(columns={0: 'txs'})\n",
    "    df_to = pd.DataFrame(dict(to_count).values(), index=dict(to_count).keys()).rename(columns={0: 'txs'})\n",
    "    df_from.to_csv('plots/{}/{}_tx_count_from.csv'.format(token, token))\n",
    "    df_to.to_csv('plots/{}/{}_tx_count_to.csv'.format(token, token))\n",
    "    return\n",
    "    \n",
    "    \n",
    "usdt = [tether_chunk_0, tether_chunk_1, tether_chunk_2, tether_chunk_3, tether_chunk_4, tether_chunk_5]\n",
    "from_to_tx_counter(usdt)\n",
    "from_to_tx_counter([usdc_transfer])\n",
    "from_to_tx_counter([paxos_transfer])\n",
    "from_to_tx_counter([dai_transfer])\n",
    "from_to_tx_counter([trueusd_transfer])\n",
    "from_to_tx_counter([husd_transfer])\n",
    "from_to_tx_counter([binanceusd_transfer])\n",
    "from_to_tx_counter([sai_transfer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create plot data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfers over date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(df):\n",
    "    dates = df.apply(lambda x: str(datetime.utcfromtimestamp(x))[:10])\n",
    "    txs = list(Counter(dates).values())\n",
    "    \n",
    "    a = dates.iloc[0]\n",
    "    b = dates.iloc[-1]\n",
    "    idx = pd.date_range(a,b)\n",
    "    \n",
    "    df = pd.DataFrame(txs, index=np.unique(dates), columns=['txs'] )\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    df = df.reindex(idx, fill_value=0)\n",
    "    \n",
    "    da, tx = df.index.tolist(), df['txs'].tolist()\n",
    "    return da, tx\n",
    "\n",
    "def create_plot_txs_over_date(df):\n",
    "    dates =  []\n",
    "    txs = []\n",
    "    token = df.split('/')[1]\n",
    "    for chunk in pd.read_csv(df, chunksize=100000):\n",
    "        da, tx = extract_data(chunk['timestamp'])\n",
    "        dates = dates + da\n",
    "        txs = txs + tx\n",
    "    df = pd.DataFrame({'dates': dates, 'txs': txs}).groupby('dates', as_index=False).sum()\n",
    "    df.to_csv('plots/{}/{}_txs_over_date.csv'.format(token, token))\n",
    "    return\n",
    "    \n",
    "create_plot_txs_over_date(tether_transfer)\n",
    "create_plot_txs_over_date(usdc_transfer)\n",
    "create_plot_txs_over_date(paxos_transfer)\n",
    "create_plot_txs_over_date(dai_transfer)\n",
    "create_plot_txs_over_date(trueusd_transfer)\n",
    "create_plot_txs_over_date(binanceusd_transfer)\n",
    "create_plot_txs_over_date(husd_transfer)\n",
    "create_plot_txs_over_date(sai_transfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfers to new addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tos = set()\n",
    "def _add(x):\n",
    "    global tos\n",
    "    tos.add(x)\n",
    "    return 1\n",
    "\n",
    "def extract_uniques(df):\n",
    "    dates = df['timestamp'].apply(lambda x: str(datetime.utcfromtimestamp(x))[:10])\n",
    "    un = df['txto'].apply(lambda x: _add(x) if x not in tos else 0)\n",
    "    \n",
    "    a = dates.iloc[0]\n",
    "    b = dates.iloc[-1]\n",
    "    idx = pd.date_range(a,b)\n",
    "    df = pd.DataFrame({'dates':dates, 'uniques':un})\n",
    "    df = df.groupby('dates', as_index = False).sum()\n",
    "    df = df.set_index('dates')\n",
    "    \n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    df = df.reindex(idx, fill_value=0)\n",
    "    return df.index.tolist(), df['uniques'].tolist()\n",
    "\n",
    "def create_plot_unique_recipients_over_date(df):\n",
    "    global tos\n",
    "    dates =  []\n",
    "    txs = []\n",
    "    for i in df:\n",
    "        token = i.split('/')[1]\n",
    "        for chunk in pd.read_csv(i, chunksize=1000000):\n",
    "            da, tx = extract_uniques(chunk[['timestamp', 'txto']])\n",
    "            dates = dates + da\n",
    "            txs = txs + tx\n",
    "        \n",
    "    df = pd.DataFrame({'dates': dates, 'txs': txs}).groupby('dates', as_index=False).sum()\n",
    "    df.to_csv('plots/{}/{}_unique_recipients_over_date.csv'.format(token, token))\n",
    "    tos = set()\n",
    "    return\n",
    "\n",
    "    \n",
    "df = [tether_chunk_0, tether_chunk_1, tether_chunk_2, tether_chunk_3, tether_chunk_4, tether_chunk_5]\n",
    "create_plot_unique_recipients_over_date(df)\n",
    "\n",
    "create_plot_unique_recipients_over_date([usdc_transfer])\n",
    "create_plot_unique_recipients_over_date([paxos_transfer])\n",
    "create_plot_unique_recipients_over_date([husd_transfer])\n",
    "create_plot_unique_recipients_over_date([binanceusd_transfer])\n",
    "create_plot_unique_recipients_over_date([trueusd_transfer])\n",
    "create_plot_unique_recipients_over_date([dai_transfer])\n",
    "create_plot_unique_recipients_over_date([sai_transfer])#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfers from new addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "froms = set()\n",
    "def _add(x):\n",
    "    global froms\n",
    "    froms.add(x)\n",
    "    return 1\n",
    "\n",
    "def extract_uniques(df):\n",
    "    dates = df['timestamp'].apply(lambda x: str(datetime.utcfromtimestamp(x))[:10])\n",
    "    un = df['txfrom'].apply(lambda x: _add(x) if x not in froms else 0)\n",
    "    a = dates.iloc[0]\n",
    "    b = dates.iloc[-1]\n",
    "    idx = pd.date_range(a,b)\n",
    "    df = pd.DataFrame({'dates':dates, 'uniques':un})\n",
    "    df = df.groupby('dates', as_index = False).sum()\n",
    "    df = df.set_index('dates')\n",
    "    \n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    df = df.reindex(idx, fill_value=0)\n",
    "    return df.index.tolist(), df['uniques'].tolist()\n",
    "\n",
    "\n",
    "def create_plot_unique_senders_over_date(df):\n",
    "    dates =  []\n",
    "    txs = []\n",
    "    for i in df:\n",
    "        token = i.split('/')[1]\n",
    "        for chunk in pd.read_csv(i, chunksize=10000000):\n",
    "            da, tx = extract_uniques(chunk[['timestamp', 'txfrom']])\n",
    "            dates = dates + da\n",
    "            txs = txs + tx\n",
    "    \n",
    "    df = pd.DataFrame({'dates': dates, 'txs': txs}).groupby('dates', as_index=False).sum()\n",
    "    df.to_csv('plots/{}/{}_unique_senders_over_date.csv'.format(token, token))\n",
    "    return\n",
    "    \n",
    "df = [tether_chunk_0, tether_chunk_1, tether_chunk_2, tether_chunk_3, tether_chunk_4, tether_chunk_5]\n",
    "create_plot_unique_senders_over_date(df)\n",
    "\n",
    "create_plot_unique_senders_over_date([usdc_transfer])\n",
    "create_plot_unique_senders_over_date([paxos_transfer])\n",
    "create_plot_unique_senders_over_date([husd_transfer])\n",
    "create_plot_unique_senders_over_date([binanceusd_transfer])\n",
    "create_plot_unique_senders_over_date([trueusd_transfer])\n",
    "create_plot_unique_senders_over_date([dai_transfer])\n",
    "create_plot_unique_senders_over_date([sai_transfer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique Transfers per day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Recipients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timestamp first transfer event of contract\n",
    "ts_tether = 1511827200\n",
    "ts_usdc = 1536537600\n",
    "ts_paxos = 1536537600\n",
    "ts_dai = 1573603200\n",
    "ts_sai = 1513555200\n",
    "ts_trueusd = 1520208000\n",
    "ts_husd = 1563580800\n",
    "ts_binanceusd = 1568073600\n",
    "\n",
    "\n",
    "def get_unique_recipients_per_day(df, ts):\n",
    "    unique = dict()\n",
    "    counter = 0\n",
    "    token = df.split('/')[1]\n",
    "    df = pd.read_csv(df)[['timestamp', 'txto']]\n",
    "    while ts + 86400*counter < 1593561600:\n",
    "        timefrom = ts + 86400*counter\n",
    "        timeto = ts + 86400*(counter+1)\n",
    "        uniques = len(df[(df['timestamp'] >=timefrom) & (df['timestamp'] < timeto)]['txto'].unique())\n",
    "        date = str(datetime.utcfromtimestamp(timefrom))[:10]\n",
    "        if date in unique.keys():\n",
    "            unique[date] += uniques\n",
    "        else:\n",
    "            unique[date] = uniques\n",
    "        counter += 1\n",
    "    \n",
    "    _df = pd.DataFrame(unique.values(), index=unique.keys()).rename(columns={0:'txs'})\n",
    "    _df.to_csv('plots/{}/{}_unique_recipients_per_day_over_date.csv'.format(token, token))\n",
    "\n",
    "\n",
    "get_unique_recipients_per_day(tether_transfer, ts_tether)\n",
    "get_unique_recipients_per_day(usdc_transfer, ts_usdc)\n",
    "get_unique_recipients_per_day(paxos_transfer, ts_paxos)\n",
    "get_unique_recipients_per_day(dai_transfer, ts_dai)\n",
    "get_unique_recipients_per_day(sai_transfer, ts_sai)\n",
    "get_unique_recipients_per_day(husd_transfer, ts_husd)\n",
    "get_unique_recipients_per_day(trueusd_transfer, ts_trueusd)\n",
    "get_unique_recipients_per_day(binanceusd_transfer, ts_binanceusd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Senders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timestamp first transfer event of contract\n",
    "ts_tether = 1511827200\n",
    "ts_usdc = 1536537600\n",
    "ts_paxos = 1536537600\n",
    "ts_dai = 1573603200\n",
    "ts_sai = 1513555200\n",
    "ts_trueusd = 1520208000\n",
    "ts_husd = 1563580800\n",
    "ts_binanceusd = 1568073600\n",
    "\n",
    "\n",
    "def get_unique_senders_per_day(df, ts):\n",
    "    unique = dict()\n",
    "    counter = 0\n",
    "    token = df.split('/')[1]\n",
    "    df = pd.read_csv(df)[['timestamp', 'txfrom']]\n",
    "    while ts + 86400*counter < 1593561600:\n",
    "        timefrom = ts + 86400*counter\n",
    "        timeto = ts + 86400*(counter+1)\n",
    "        uniques = len(df[(df['timestamp'] >=timefrom) & (df['timestamp'] < timeto)]['txfrom'].unique())\n",
    "        date = str(datetime.utcfromtimestamp(timefrom))[:10]\n",
    "        if date in unique.keys():\n",
    "            unique[date] += uniques\n",
    "        else:\n",
    "            unique[date] = uniques\n",
    "        counter += 1\n",
    "\n",
    "    _df = pd.DataFrame(unique.values(), index=unique.keys()).rename(columns={0:'txs'})\n",
    "    _df.to_csv('plots/{}/{}_unique_senders_per_day_over_date.csv'.format(token, token))\n",
    "    \n",
    "get_unique_senders_per_day(tether_transfer, ts_tether)\n",
    "get_unique_senders_per_day(usdc_transfer, ts_usdc)\n",
    "get_unique_senders_per_day(paxos_transfer, ts_paxos)\n",
    "get_unique_senders_per_day(dai_transfer, ts_dai)\n",
    "get_unique_senders_per_day(sai_transfer, ts_sai)\n",
    "get_unique_senders_per_day(husd_transfer, ts_husd)\n",
    "get_unique_senders_per_day(trueusd_transfer, ts_trueusd)\n",
    "get_unique_senders_per_day(binanceusd_transfer, ts_binanceusd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average transfer value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot_avg_txvalue(df, token, decimals):   \n",
    "    df = df[['timestamp', 'txvalue']]\n",
    "    dates = df['timestamp'].apply(lambda x: str(datetime.utcfromtimestamp(x))[:10])\n",
    "    txvalue = df['txvalue']\n",
    "    df = pd.DataFrame({'dates': dates, 'txvalue': txvalue.astype(float)/(10**decimals)})\n",
    "    a = dates.iloc[0]\n",
    "    b = dates.iloc[-1]\n",
    "    idx = pd.date_range(a,b)\n",
    "    df = df.groupby('dates', as_index=False).mean()\n",
    "    df = df.set_index('dates')\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    df = df.reindex(idx, fill_value=0)\n",
    "    df.to_csv('plots/{}/{}_avg_value_over_date.csv'.format(token, token))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average gas price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot_avg_gas(df, token):\n",
    "    df = df[['timestamp', 'gas_price', 'gas_used']]\n",
    "    dates = df['timestamp'].apply(lambda x: str(datetime.utcfromtimestamp(x))[:10])\n",
    "    df = pd.DataFrame({'dates': dates, 'gas': df['gas_price']*df['gas_used']/(10**18)})\n",
    "    a = dates.iloc[0]\n",
    "    b = dates.iloc[-1]\n",
    "    idx = pd.date_range(a,b)\n",
    "    df = df.groupby('dates', as_index=False).mean()\n",
    "    df = df.set_index('dates')\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    df = df.reindex(idx, fill_value=0)\n",
    "    df.to_csv('plots/{}/{}_avg_gas_over_date.csv'.format(token, token))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [(paxos_transfer, 18), (usdc_transfer, 6), (husd_transfer, 8), \n",
    "          (dai_transfer, 18), (sai_transfer, 18), (trueusd_transfer, 18), (binanceusd_transfer, 18)]:\n",
    "    df = pd.read_csv(i[0])\n",
    "    token = i[0].split('/')[1]\n",
    "    create_plot_avg_txvalue(df, token, i[1])\n",
    "    create_plot_avg_gas(df, token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circulating supply \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare tokens without Mint/Burn Events (DAI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dai_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mint = df[df['txfrom'] == '0x0000000000000000000000000000000000000000'].reset_index().drop('index', axis = 1).rename(columns={'txfrom': 'address'})\n",
    "burn = df[df['txto'] == '0x0000000000000000000000000000000000000000'].reset_index().drop('index', axis = 1).rename(columns={'txfrom': 'address'})\n",
    "\n",
    "mint.to_csv('data/dai/mint/dai_mint.csv')\n",
    "burn.to_csv('data/dai/burn/dai_burn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Plot for circulating supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_plot_circulating_amount(df_mint, df_burn):\n",
    "    token = df_mint.split('/')[1]\n",
    "    _issue = pd.read_csv(df_mint)\n",
    "    _destroyedblackfunds = pd.read_csv(df_burn)\n",
    "    if type(_issue['txvalue'][0])==type(str()):\n",
    "        _issue['txvalue'] = _issue['txvalue'].astype(float)\n",
    "        _destroyedblackfunds['txvalue'] = _destroyedblackfunds['txvalue'].astype(float)\n",
    "    dbf = _destroyedblackfunds.loc[:, ['timestamp', 'txvalue']]\n",
    "    iss = _issue.loc[:, ['timestamp', 'txvalue']]\n",
    "    dbf['txvalue'] = dbf['txvalue']*-1\n",
    "    dfis = pd.concat([dbf,iss])\n",
    "    dfis = dfis.sort_values('timestamp', axis = 0).reset_index().loc[:,['timestamp', 'txvalue']]\n",
    "    dfis['utc'] = dfis['timestamp'].apply(lambda x: str(datetime.utcfromtimestamp(x))[0:10])\n",
    "    dfis = dfis[['utc', 'txvalue']]\n",
    "    dfis = dfis.groupby('utc').sum()\n",
    "    a = dfis.index[0]\n",
    "    b = dfis.index[-1]\n",
    "    idx = pd.date_range(a,b)\n",
    "    dfis.index = pd.DatetimeIndex(dfis.index)\n",
    "    cirulating_amount = dfis.reindex(idx, fill_value=0)\n",
    "    cirulating_amount.to_csv('plots/{}/{}_circulating_supply.csv'.format(token, token))\n",
    "    return cirulating_amount\n",
    "\n",
    "create_plot_circulating_amount(tether_issue, tether_destroyedblackfunds)\n",
    "create_plot_circulating_amount(usdc_mint, usdc_burn)\n",
    "create_plot_circulating_amount(paxos_mint, paxos_burn)\n",
    "create_plot_circulating_amount(dai_mint, dai_burn)\n",
    "create_plot_circulating_amount(trueusd_mint, trueusd_burn)\n",
    "create_plot_circulating_amount(husd_mint, husd_burn)\n",
    "create_plot_circulating_amount(binanceusd_mint, binanceusd_burn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulated Balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsum = pd.Series()\n",
    "def create_cum_sum(df, st):\n",
    "    global cumsum\n",
    "    cs = df.cumsum() + st\n",
    "    end = cs.iloc[-1]\n",
    "    cumsum = cumsum.append(cs)\n",
    "    return end\n",
    "\n",
    "def create_cum_bal(df):\n",
    "    global cumsum\n",
    "    start = 0\n",
    "    token = df.split(\"/\")[1]\n",
    "    for i in pd.read_csv(df, chunksize = 1000000):\n",
    "        i = i['txvalue']\n",
    "        i = i[i>0]\n",
    "        if len(i) > 0:\n",
    "            start = create_cum_sum(i, st = start)\n",
    "    y = cumsum/cumsum.iloc[-1] #Supply 01 July 20\n",
    "    x = (np.arange(start = 0 , stop = len(cumsum), step = 1)/len(cumsum))*100\n",
    "    df = pd.read_csv('plots/{}/{}_balances.csv'.format(token, token))\n",
    "    df = df.rename(columns={'Unnamed: 0': 'address', 'txvalue': 'balance'})\n",
    "    df = df[df['balance']>0]\n",
    "    df = df.reset_index()[['address', 'balance']]\n",
    "    df['cum'] = cumsum.reset_index()[0]\n",
    "    df.to_csv('plots/{}/{}_positive_cumulated_balances.csv'.format(token, token))\n",
    "    cumsum = pd.Series()\n",
    "\n",
    "create_cum_bal('plots/tether/tether_balances.csv')\n",
    "create_cum_bal('plots/usdc/usdc_balances.csv')\n",
    "create_cum_bal('plots/paxos/paxos_balances.csv')\n",
    "create_cum_bal('plots/dai/dai_balances.csv')\n",
    "create_cum_bal('plots/binanceusd/binanceusd_balances.csv')\n",
    "create_cum_bal('plots/husd/husd_balances.csv')\n",
    "create_cum_bal('plots/trueusd/trueusd_balances.csv')\n",
    "create_cum_bal('plots/sai/sai_balances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tether fix\n",
    "df2 = pd.read_csv('plots/tether/tether_positive_cumulated_balances.csv', index_col=0)\n",
    "df2.iloc[1:].reset_index().loc[:, 'address':'cum'].to_csv('plots/tether/tether_positive_cumulated_balances.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Transfer count over whole ecosystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_tether = pd.read_csv(tether_tx_count_from, index_col='Unnamed: 0')\n",
    "to_tether = pd.read_csv(tether_tx_count_to, index_col='Unnamed: 0')\n",
    "fr_dai = pd.read_csv(dai_tx_count_from, index_col='Unnamed: 0')\n",
    "to_dai = pd.read_csv(dai_tx_count_to, index_col='Unnamed: 0')\n",
    "fr_usdc = pd.read_csv(usdc_tx_count_from, index_col='Unnamed: 0')\n",
    "to_usdc = pd.read_csv(usdc_tx_count_to, index_col='Unnamed: 0')\n",
    "fr_paxos = pd.read_csv(paxos_tx_count_from, index_col='Unnamed: 0')\n",
    "to_paxos = pd.read_csv(paxos_tx_count_to, index_col='Unnamed: 0')\n",
    "fr_trueusd = pd.read_csv(trueusd_tx_count_from, index_col='Unnamed: 0')\n",
    "to_trueusd = pd.read_csv(trueusd_tx_count_to, index_col='Unnamed: 0')\n",
    "fr_binanceusd = pd.read_csv(binanceusd_tx_count_from, index_col='Unnamed: 0')\n",
    "to_binanceusd = pd.read_csv(binanceusd_tx_count_to, index_col='Unnamed: 0')\n",
    "fr_husd = pd.read_csv(husd_tx_count_from, index_col='Unnamed: 0')\n",
    "to_husd = pd.read_csv(husd_tx_count_to, index_col='Unnamed: 0')\n",
    "\n",
    "fr_new = fr_tether.append([fr_dai, fr_usdc, fr_paxos, fr_trueusd, fr_binanceusd, fr_husd])\n",
    "fr_new = fr_new.groupby(fr_new.index)['txs'].sum()\n",
    "fr_new.to_csv('plots/summary/from.csv')\n",
    "\n",
    "to_new = to_tether.append([to_dai, to_usdc, to_paxos, to_trueusd, to_binanceusd, to_husd])\n",
    "to_new = to_new.groupby(to_new.index)['txs'].sum()\n",
    "to_new.to_csv('plots/summary/to.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "master_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
