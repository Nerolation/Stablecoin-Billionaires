{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Stablecoin Billionaires<br> Descriptive Analysis of the Ethereum-based <br>\n",
    "    Stablecoin ecosystem</center></h1>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center> by Anton Wahrst√§tter<br>01.07.2020</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center> Script to fetch Event data from Ethereum and store it as CSV</h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to add another token, make the following additions\n",
    "# 1. Add the Contract address of the token contract to the tokens\n",
    "# 2. If the Event isn't already inlcuded, add it too (pay adittion to the exact expression of the code)\n",
    "# 3. If you you have added a new Event manually, you have to adapt the functions handle_result \n",
    "#    and save_chunk_to_csv too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libriaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import sha3\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs and Constants "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CALLS_PER_SECOND = 5 # max calls per second, Etherscan allows 5 at max\n",
    "API = 'https://api.etherscan.io/api?module=logs&action=getLogs' # API endpoint\n",
    "MAX_EVENTS = 1000 # Max events per request, Etherscan returns 1000 at max\n",
    "CHUNKADJUSTER = 200 # The level, when the requested blocksize should be increased \n",
    "LINE = '-------------------------------------------------------'\n",
    "LINE = LINE+LINE\n",
    "print('Enter your Etherscan API Key:')\n",
    "KEY = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = ''\n",
    "print('Token: (lowercase)')\n",
    "_TOKEN = input().lower()\n",
    "\n",
    "    #DOESN'T emit Transfers for mint and burn but Issue and DestroyedBlackFunds\n",
    "if _TOKEN == 'tether':\n",
    "    TETHER = '0xdAC17F958D2ee523a2206206994597C13D831ec7'\n",
    "    TOKEN = TETHER\n",
    "    \n",
    "    #emits Transfers for mint and burn + Mint and Burn\n",
    "if _TOKEN == 'usdc':\n",
    "    USDC = '0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48'\n",
    "    TOKEN = USDC\n",
    "    \n",
    "    #emits Transfers for mint and burn + SupplyIncreased and SupplyDecreased\n",
    "if _TOKEN == 'paxos':\n",
    "    PAXOS = '0x8e870d67f660d95d5be530380d0ec0bd388289e1'\n",
    "    TOKEN = PAXOS   \n",
    "\n",
    "    #emits Transfers for mint and burn but no specific event\n",
    "if _TOKEN == 'dai':\n",
    "    DAI = '0x6B175474E89094C44Da98b954EedeAC495271d0F'\n",
    "    TOKEN = DAI \n",
    "\n",
    "     #emits Transfers for mint and burn + Mint and Burn\n",
    "if _TOKEN == 'trueusd':\n",
    "    TRUEUSD = '0x0000000000085d4780B73119b644AE5ecd22b376'\n",
    "    TOKEN = TRUEUSD \n",
    "    \n",
    "if _TOKEN == 'oldtrueusd':\n",
    "    OLDTRUEUSD = '0x8dd5fbCe2F6a956C3022bA3663759011Dd51e73E'\n",
    "    TOKEN = OLDTRUEUSD \n",
    "\n",
    "    #emits Transfers for mint and burn + Issue and Redeem\n",
    "if _TOKEN == 'husd':\n",
    "    HUSD = '0xdf574c24545e5ffecb9a659c229253d4111d87e1' \n",
    "    TOKEN = HUSD \n",
    "\n",
    "    #emits Transfers for mint and burn + SupplyIncreased and SupplyDecreased\n",
    "if _TOKEN == 'binanceusd':\n",
    "    BINANCEUSD = '0x4Fabb145d64652a948d72533023f6E7A623C7C53' \n",
    "    TOKEN = BINANCEUSD \n",
    "    \n",
    "       \n",
    "if TOKEN:\n",
    "    print('Selected Token: {}'.format(_TOKEN))\n",
    "else:\n",
    "    raise Exception('Token not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Eventname: (lowercase)')\n",
    "EVENT = ''\n",
    "_EVENT = input().lower()\n",
    "\n",
    "if _EVENT == 'transfer':\n",
    "    TRANSFER = '0x' + sha3.keccak_256('Transfer(address,address,uint256)'.encode('utf-8')).hexdigest()\n",
    "    EVENT = TRANSFER\n",
    "if _EVENT == 'issue':\n",
    "    ISSUE = '0x' + sha3.keccak_256('Issue(uint256)'.encode('utf-8')).hexdigest()\n",
    "    EVENT = ISSUE \n",
    "if _EVENT == 'redeem':\n",
    "    REDEEM = '0x' + sha3.keccak_256('Redeem(uint256)'.encode('utf-8')).hexdigest()\n",
    "    EVENT = REDEEM\n",
    "if _EVENT == 'issuehusd':\n",
    "    ISSUE = '0x' + sha3.keccak_256('Issue(address,uint256)'.encode('utf-8')).hexdigest()\n",
    "    EVENT = ISSUE \n",
    "if _EVENT == 'redeemhusd':\n",
    "    REDEEM = '0x' + sha3.keccak_256('Redeem(address,uint256)'.encode('utf-8')).hexdigest()\n",
    "    EVENT = REDEEM\n",
    "if _EVENT == 'destroyedblackfunds':\n",
    "    DESTROYED = '0x' + sha3.keccak_256('DestroyedBlackFunds(address,uint256)'.encode('utf-8')).hexdigest()\n",
    "    EVENT = DESTROYED\n",
    "if _EVENT == 'approve':\n",
    "    APPROVE = '0x' + sha3.keccak_256('Approval(address,address,uint256)'.encode('utf-8')).hexdigest()\n",
    "    EVENT = APPROVE\n",
    "if _EVENT == 'mint':\n",
    "    MINT = '0x' + sha3.keccak_256('Mint(address,uint256)'.encode('utf-8')).hexdigest()\n",
    "    EVENT = MINT\n",
    "if _EVENT == 'mintusdc':\n",
    "    MINT = '0x' + sha3.keccak_256('Mint(address,address,uint256)'.encode('utf-8')).hexdigest()\n",
    "    EVENT = MINT\n",
    "if _EVENT == 'burn':\n",
    "    BURN = '0x' + sha3.keccak_256('Burn(address,uint256)'.encode('utf-8')).hexdigest()\n",
    "    EVENT = BURN\n",
    "if _EVENT == 'supplyincreased':\n",
    "    SUPPLYINCREASED = '0x' + sha3.keccak_256('SupplyIncreased(address,uint256)'.encode('utf-8')).hexdigest()\n",
    "    EVENT = SUPPLYINCREASED    \n",
    "if _EVENT == 'supplydecreased':\n",
    "    SUPPLYDECREASED = '0x' + sha3.keccak_256('SupplyDecreased(address,uint256)'.encode('utf-8')).hexdigest()\n",
    "    EVENT = SUPPLYDECREASED \n",
    "\n",
    "    \n",
    "if EVENT:\n",
    "    print('\\nSelected Event: {}'.format(_EVENT))\n",
    "else:\n",
    "    raise Exception('Check name of events in the Github Docs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Startblock:')\n",
    "STARTBLOCK = int(input())\n",
    "print('Endblock:')\n",
    "ENDBLOCK = int(input())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Storage Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Filename: (default: data/{}/{}/{}_{}.csv)'.format(_TOKEN, _EVENT, _TOKEN, _EVENT))   \n",
    "FILENAME = input()\n",
    "if FILENAME == '':\n",
    "    FILENAME = 'data/{}/{}/{}_{}.csv'.format(_TOKEN, _EVENT, _TOKEN, _EVENT)\n",
    "print('\\nFilename: {}'.format(FILENAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Select CHUNKSIZE: (how many blocks should at the beginning be processed within one API-request - then autoregulated depending on the blocksizes)')\n",
    "CHUNKSIZE = input()\n",
    "if CHUNKSIZE == '':\n",
    "    CHUNKSIZE = ENDBLOCK - STARTBLOCK\n",
    "CHUNKSIZE = int(CHUNKSIZE)\n",
    "\n",
    "print('Select Max. CHUNKSIZE: (depends on number of events, f.e. take max. 20,000 for Transfer Events, but much more for Issue Events)')\n",
    "MAXCHUNKSSIZE = input()\n",
    "if MAXCHUNKSSIZE == '':\n",
    "    MAXCHUNKSSIZE = ENDBLOCK - STARTBLOCK     \n",
    "MAXCHUNKSSIZE = int(MAXCHUNKSSIZE)\n",
    "chunklength = np.array([CHUNKADJUSTER*1.3]*10) # intially set 30% higher than chunkadjuster \n",
    "                                               # keeps track of number of events within a response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_hex(string):\n",
    "    if str(string) == '0x':\n",
    "        return 0\n",
    "    return int(str(string),16)\n",
    "\n",
    "# main function - performs request,\n",
    "def request_events(block_from, block_to, event, token, bl_start):\n",
    "    global CHUNK, CHUNKSIZE, counter, block_time_avg, chunklength\n",
    "    ev_amount = MAX_EVENTS # set ev_amount to MAX_EVENT to start while loop\n",
    "    increased = False # binary variable to tell the executing function if the requested block range increased\n",
    "    inc_lock = False # binary variable to block increases - needed if very few blocks are requested\n",
    "    while  ev_amount >= MAX_EVENTS:\n",
    "        res_code = 400 # initally set response to 400 to enter loop\n",
    "        rep = 0 # repetitions counter\n",
    "        while res_code != 200:\n",
    "            time.sleep(0.1)\n",
    "            rep += 1\n",
    "            query = '{}&fromBlock={}&toBlock={}&topic0={}&topic0_1_opr=and&address={}&apikey={}'.format(API,\n",
    "                                                                                               str(block_from),\n",
    "                                                                                               str(block_to),\n",
    "                                                                                               event,\n",
    "                                                                                               token,\n",
    "                                                                                               KEY)\n",
    "            res = requests.get(query) # actual request\n",
    "            res_code = res.status_code # get status code of request\n",
    "            if rep > 2 and res_code != 200: # if failed - wait and try again\n",
    "                time.sleep(5)\n",
    "                print('connection problem occured - will try again - {}'.format(rep))\n",
    "                if rep == 5: # if failed 5 times, wait longer and throw exception\n",
    "                    time.sleep(120)\n",
    "                    raise Exception('\\n\\n\\n\\n\\nConnection problem to API\\n\\n\\n\\n\\n')\n",
    "                    \n",
    "            if json.loads(res.content.decode())[\"result\"] == None: \n",
    "                res_code = 400 # if request successfull but no content - retry by setting res_code to 400\n",
    "        result = json.loads(res.content)['result'] # get result of response\n",
    "        if result == None:\n",
    "            print(res.content)\n",
    "            \n",
    "        ev_amount = len(result) # get number of events that are included in the response\n",
    "        chunklength = np.append(chunklength, [ev_amount]) # add lenght to chunklength \n",
    "        \n",
    "        # -------Start of Block Range Adjuster-------\n",
    "        if ev_amount >= MAX_EVENTS:\n",
    "            if 0 < CHUNKSIZE <= 4:\n",
    "                factor = 1\n",
    "            else:\n",
    "                factor = 4\n",
    "            print('--- Length of results: {} ---'.format(ev_amount))\n",
    "            block_to -= round((block_to - block_from)/factor)\n",
    "            CHUNKSIZE = block_to - block_from\n",
    "            print('--- Reducing CHUNKSIZE to: {} ---'.format(CHUNKSIZE))\n",
    "            inc_lock = True\n",
    "            \n",
    "        if np.mean(chunklength[-10:]) < CHUNKADJUSTER and CHUNKSIZE*1.125 < MAXCHUNKSSIZE and inc_lock == False:\n",
    "            _block_to = block_to\n",
    "            if CHUNKSIZE <= 4:               \n",
    "                factor = 1\n",
    "            else:\n",
    "                factor = 8\n",
    "            print('+++ Length of results: {} +++'.format(ev_amount))\n",
    "            block_to += round((block_to - block_from)/factor)\n",
    "            CHUNKSIZE = block_to - block_from\n",
    "            print('+++ Increasing CHUNKSIZE to: {} +++'.format(CHUNKSIZE))\n",
    "            increased = round((_block_to - block_from)/factor)\n",
    "        # -------End of Block Range Adjuster-------\n",
    "        \n",
    "    counter += 1 # counter for printing a headline      \n",
    "    handle_result(result) # fetch data from response and add it to the chunk\n",
    "    bl_delta = datetime.now().timestamp() - bl_start  # request duration\n",
    "    block_time_avg = np.append(block_time_avg, [bl_delta]) # average time to request a block\n",
    "    if len(block_time_avg) > 5: # keep track of average of the last 5 only\n",
    "        block_time_avg = block_time_avg[1:]\n",
    "    if counter % 1 == 0: # if allways, can easily be adapted to only print every 2nd time\n",
    "        try: # print in the case of an increased blockrange\n",
    "            print_logs(True, counter, (block_from, block_to-increased), CHUNK[-1][0], ev_amount, np.mean(block_time_avg))\n",
    "            block_time_avg = np.array([])\n",
    "        except:\n",
    "            print_logs(True, counter, (block_from, block_to), '-', ev_amount, np.mean(block_time_avg))\n",
    "            block_time_avg = np.array([])\n",
    "\n",
    "    return increased\n",
    "\n",
    "# takes the http request and adds it to the CHUNK\n",
    "def handle_result(result):\n",
    "    global CHUNK\n",
    "    for e in result:\n",
    "        value = from_hex(e['data'])\n",
    "        block_number = from_hex(e['blockNumber'])\n",
    "        time_stamp = from_hex(e['timeStamp'])\n",
    "        tx_hash = e['transactionHash']\n",
    "        tx_index = from_hex(e['transactionIndex'])\n",
    "        gas_price = from_hex(e['gasPrice'])\n",
    "        gas_used = from_hex(e['gasUsed'])\n",
    "\n",
    "        if _EVENT in ['transfer', 'approve']:\n",
    "            tx_from, tx_to = '0x' + e['topics'][1][-40:], '0x' + e['topics'][2][-40:]\n",
    "            CHUNK.append([time_stamp, block_number, tx_index, tx_hash, tx_from, tx_to, value, gas_price, gas_used])\n",
    "\n",
    "        if _EVENT in ['issue', 'redeem']:\n",
    "            CHUNK.append([time_stamp, block_number, tx_index, tx_hash, value, gas_price, gas_used])\n",
    "\n",
    "        if _EVENT in ['destroyedblackfunds']:\n",
    "            address = '0x' + e['data'][26:66]\n",
    "            funds = from_hex('0x' + e['data'][-20:])\n",
    "            CHUNK.append([time_stamp, block_number, tx_index, tx_hash, address, funds, gas_price, gas_used])\n",
    "        \n",
    "        if _EVENT in ['mint', 'burn', 'supplyincreased', 'supplydecreased', 'issuehusd', 'redeemhusd']:\n",
    "            address = '0x' + e['topics'][1][-40:]\n",
    "            CHUNK.append([time_stamp, block_number, tx_index, tx_hash, address, value, gas_price, gas_used])\n",
    "            \n",
    "        if _EVENT in ['mintusdc']:\n",
    "            address = '0x' + e['topics'][2][-40:]\n",
    "            CHUNK.append([time_stamp, block_number, tx_index, tx_hash, address, value, gas_price, gas_used])\n",
    "            \n",
    "    return []\n",
    "\n",
    "\n",
    "# print logs\n",
    "def print_logs(arg, *args):\n",
    "    counter, block_number, bl_time_stamp, ev_amount, block_time_avg = args\n",
    "    bl_f, bl_t = block_number\n",
    "    if arg:\n",
    "        if counter == 1:\n",
    "            print('{:<8}{:<25}{:<20}{:<20}{:<10}{:<14}{}'.format('Index',\n",
    "                                                                 'UTC Timestamp',\n",
    "                                                                 'Block Nr.',\n",
    "                                                                 'Block Timestamp',\n",
    "                                                                 'Events',\n",
    "                                                                 'Requests/s',\n",
    "                                                                 'Blocks/s'))\n",
    "            print(LINE)\n",
    "        \n",
    "        \n",
    "        print('{:<6}{:<25}{:<20}{:<25}{:<11}{:<11.2f}{:d}'.format(counter,\n",
    "                                                                  str(datetime.utcnow())[0:-7],\n",
    "                                                                  str(bl_f) + '/' + str(bl_t),\n",
    "                                                                  bl_time_stamp if bl_time_stamp == '-' else datetime.utcfromtimestamp(bl_time_stamp).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                                                                  ev_amount,\n",
    "                                                                  1/block_time_avg,\n",
    "                                                                  int((bl_t-bl_f)/block_time_avg)\n",
    "                                                                  ))\n",
    "\n",
    "# save current CHUNK to CSV and reset CHUNK\n",
    "def save_chunk_to_csv():\n",
    "    global CHUNK\n",
    "    if not os.path.exists(FILENAME):\n",
    "        if _EVENT in ['transfer', 'approve']:\n",
    "            df = pd.DataFrame(columns=['timestamp','blocknumber','txindex','txhash','txfrom','txto', 'txvalue', 'gas_price', 'gas_used'])\n",
    "        if _EVENT in ['issue', 'redeem']:\n",
    "            df = pd.DataFrame(columns=['timestamp','blocknumber','txindex','txhash', 'txvalue', 'gas_price', 'gas_used'])\n",
    "        if _EVENT in ['destroyedblackfunds', 'mint', 'mintusdc', 'burn', 'supplyincreased', 'supplydecreased', 'issuehusd', 'redeemhusd']:\n",
    "            df = pd.DataFrame(columns=['timestamp','blocknumber','txindex','txhash', 'address', 'txvalue', 'gas_price', 'gas_used'])\n",
    "        \n",
    "        df.to_csv(FILENAME, index = False)\n",
    "    with open(FILENAME, 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(e for e in CHUNK)  \n",
    "    CHUNK = []\n",
    "\n",
    "print('Selected Chunksize/Max-Chunksize: {}/{}'.format(CHUNKSIZE, MAXCHUNKSSIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "CHUNK = []\n",
    "block_time_avg = np.array([])\n",
    "def mine_events():\n",
    "    global STARTBLOCK, CHUNKSIZE\n",
    "    print('\\nSTART MINING: {}'.format(TOKEN))\n",
    "    print('UTC TIME: {}'.format(str(datetime.utcnow())[0:-7]))\n",
    "    print('\\nFROM BLOCK {}'.format(STARTBLOCK))\n",
    "    print('TO BLOCK {}\\n'.format(ENDBLOCK))\n",
    "    _BLOCK = STARTBLOCK\n",
    "    \n",
    "    while _BLOCK <= ENDBLOCK: \n",
    "        if CHUNKSIZE == 0:\n",
    "            CHUNKSIZE = 1\n",
    "        bl_start = datetime.now().timestamp()\n",
    "        step_t_i = _BLOCK\n",
    "        step_t_j = _BLOCK + CHUNKSIZE \n",
    "        if step_t_j > ENDBLOCK:\n",
    "            step_t_j = ENDBLOCK\n",
    "        delta = request_events(step_t_i, step_t_j, EVENT, TOKEN, bl_start)\n",
    "        save_chunk_to_csv()\n",
    "        _BLOCK = _BLOCK + CHUNKSIZE + 1 - delta\n",
    "        print('### Current Filesize: {} MB ###'.format(os.path.getsize(FILENAME)/10**6)) if _BLOCK % 50 == 0 and os.path.exists(FILENAME) else False\n",
    "        \n",
    "    print('\\nFINISHED MINING FROM BLOCK NUMBER {} TO BLOCK NUMBER {}'.format(STARTBLOCK, ENDBLOCK))\n",
    "    print('\\nFILE SAVED UNDER {}'.format(FILENAME))\n",
    "    \n",
    "\n",
    "mine_events()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "master_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
